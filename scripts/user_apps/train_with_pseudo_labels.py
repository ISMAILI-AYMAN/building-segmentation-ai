#!/usr/bin/env python3
"""
Train Building Segmentation Model with Pseudo-Labels
Uses pseudo-labels generated by our enhanced pipeline to train a deep learning model
Then evaluates the model and integrates it into our inference system
"""

import os
import sys
import cv2
import numpy as np
from pathlib import Path
import argparse
import logging
from datetime import datetime
import json
import shutil
from typing import List, Dict, Tuple, Optional
import random
import time
from tqdm import tqdm
import torch
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Add training modules to path
sys.path.append(str(Path(__file__).parent / 'training'))
from model_architectures import create_model, get_model_configs
from training_utils import get_device, DiceLoss, CombinedLoss, SegmentationMetrics, EarlyStopping, LearningRateScheduler, TrainingLogger, save_checkpoint, load_checkpoint
from train_model import ModelTrainer, get_default_config

# Add inference modules to path
sys.path.append(str(Path(__file__).parent / 'inference'))
from inference_engine import InferenceEngine
from post_processing import PostProcessor

def setup_logging():
    """Setup logging configuration"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('pseudo_label_training.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class PseudoLabelDataset(Dataset):
    """Dataset for pseudo-label training data"""
    
    def __init__(self, data_dir: str, split: str = 'train', transform=None):
        self.data_dir = Path(data_dir)
        self.split = split
        self.transform = transform
        
        # Find images and masks
        images_dir = self.data_dir / split / 'images'
        masks_dir = self.data_dir / split / 'masks'
        
        self.image_paths = list(images_dir.glob('*.png'))
        self.mask_paths = []
        
        for img_path in self.image_paths:
            mask_path = masks_dir / f"{img_path.stem}_mask.png"
            if mask_path.exists():
                self.mask_paths.append(mask_path)
            else:
                self.mask_paths.append(None)
        
        # Filter out pairs where mask doesn't exist
        valid_pairs = [(img, mask) for img, mask in zip(self.image_paths, self.mask_paths) if mask is not None]
        self.image_paths = [pair[0] for pair in valid_pairs]
        self.mask_paths = [pair[1] for pair in valid_pairs]
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # Load image and mask
        image = cv2.imread(str(self.image_paths[idx]))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        mask = cv2.imread(str(self.mask_paths[idx]), cv2.IMREAD_GRAYSCALE)
        mask = mask.astype(np.float32)  # Ensure float32 type
        mask = mask / 255.0  # Normalize to [0, 1]
        
        # Apply transformations
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']
        
        # Convert to tensor if not already
        if not isinstance(image, torch.Tensor):
            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0
        if not isinstance(mask, torch.Tensor):
            mask = torch.from_numpy(mask).float() / 255.0
        
        # Ensure mask has channel dimension to match model output
        if len(mask.shape) == 2:
            mask = mask.unsqueeze(0)  # Add channel dimension
        
        return {
            'image': image,
            'mask': mask,
            'image_path': str(self.image_paths[idx]),
            'mask_path': str(self.mask_paths[idx])
        }

def create_data_loaders(dataset_dir: str, batch_size: int = 8, image_size: Tuple[int, int] = (512, 512)):
    """Create data loaders for training"""
    
    # Define transformations
    train_transform = A.Compose([
        A.Resize(image_size[1], image_size[0]),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])
    
    val_transform = A.Compose([
        A.Resize(image_size[1], image_size[0]),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])
    
    # Create datasets
    train_dataset = PseudoLabelDataset(dataset_dir, 'train', train_transform)
    val_dataset = PseudoLabelDataset(dataset_dir, 'val', val_transform)
    test_dataset = PseudoLabelDataset(dataset_dir, 'test', val_transform)
    
    # Create data loaders with GPU optimization
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
    
    return train_loader, val_loader, test_loader

def train_model_with_pseudo_labels(
    dataset_dir: str,
    output_dir: str,
    model_type: str = 'unet',
    epochs: int = 50,
    batch_size: int = 8,
    learning_rate: float = 1e-4,
    quick_demo: bool = False
):
    """
    Train model using pseudo-labels
    
    Args:
        dataset_dir: Directory containing pseudo-label dataset
        output_dir: Output directory for trained model
        model_type: Type of model to train ('unet', 'resnet_unet', 'efficientnet_unet')
        epochs: Number of training epochs
        batch_size: Batch size for training
        learning_rate: Learning rate
        quick_demo: Whether to run a quick demo with reduced parameters
    """
    logger = setup_logging()
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Load dataset info
    dataset_info_path = Path(dataset_dir) / 'pseudo_label_dataset_info.json'
    if not dataset_info_path.exists():
        raise ValueError(f"Dataset info not found: {dataset_info_path}")
    
    with open(dataset_info_path, 'r') as f:
        dataset_info = json.load(f)
    
    logger.info(f"Training with pseudo-label dataset:")
    logger.info(f"  - Total samples: {dataset_info['total_samples']}")
    logger.info(f"  - Average mask area ratio: {dataset_info['statistics']['average_mask_area_ratio']:.3f}")
    logger.info(f"  - Model type: {model_type}")
    
    # Get image size from dataset info
    image_size = dataset_info['processing_config']['target_size']
    
    # Create data loaders
    logger.info("Creating data loaders...")
    train_loader, val_loader, test_loader = create_data_loaders(
        dataset_dir, batch_size, image_size
    )
    
    logger.info(f"Data loaders created:")
    logger.info(f"  - Train: {len(train_loader)} batches")
    logger.info(f"  - Validation: {len(val_loader)} batches")
    logger.info(f"  - Test: {len(test_loader)} batches")
    
    # Get model configuration
    model_configs = get_model_configs()
    if model_type not in model_configs:
        raise ValueError(f"Unknown model type: {model_type}. Available: {list(model_configs.keys())}")
    
    model_config = model_configs[model_type].copy()
    model_config['input_channels'] = 3
    model_config['num_classes'] = 1
    
    # Create model
    logger.info(f"Creating {model_type} model...")
    device = get_device()
    logger.info(f"Using device: {device}")
    
    model = create_model(model_config)
    model = model.to(device)
    
    logger.info(f"Model created on {device}")
    logger.info(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # GPU optimization is already enabled in get_device()
    logger.info(f"GPU acceleration enabled on {device}")
    logger.info(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    logger.info(f"CUDA version: {torch.version.cuda}")
    
    # Training configuration
    if quick_demo:
        config = {
            'model_config': model_config,
            'epochs': 10,  # Set at top level for ModelTrainer
            'optimizer': {
                'type': 'adam',
                'lr': learning_rate,
                'weight_decay': 1e-5
            },
            'scheduler': {
                'type': 'cosine',
                'T_max': 20,
                'eta_min': 1e-6
            },
            'loss': {
                'type': 'combined',
                'dice_weight': 0.6,
                'bce_weight': 0.4
            },
            'training': {
                'epochs': 10,
                'batch_size': batch_size,
                'save_freq': 2
            }
        }
    else:
        config = get_default_config()
        config['model_config'] = model_config
        config['epochs'] = epochs  # Set at top level for ModelTrainer
        config['batch_size'] = batch_size
        config['optimizer']['lr'] = learning_rate
    
    # Update config with dataset directory
    config['data_dir'] = dataset_dir
    config['output_dir'] = str(output_path / 'training')
    
    # Initialize trainer
    trainer = ModelTrainer(config)
    
    # Setup model and components
    trainer.setup_model()
    
    # Override data loaders with our custom ones
    trainer.train_loader = train_loader
    trainer.val_loader = val_loader
    trainer.test_loader = test_loader
    
    # Train model
    logger.info("Starting model training...")
    start_time = time.time()
    
    best_model_path = trainer.train()
    
    training_time = time.time() - start_time
    logger.info(f"Training completed in {training_time:.2f} seconds")
    logger.info(f"Best model saved to: {best_model_path}")
    
    # Test model
    logger.info("Testing trained model...")
    test_metrics = trainer.test_model()
    
    logger.info("Test Results:")
    for metric, value in test_metrics.items():
        logger.info(f"  - {metric}: {value:.4f}")
    
    # Save training results
    training_results = {
        'training_time': training_time,
        'test_metrics': test_metrics,
        'model_config': model_config,
        'dataset_info': dataset_info,
        'config': config
    }
    
    with open(output_path / 'training_results.json', 'w') as f:
        json.dump(training_results, f, indent=2)
    
    return best_model_path, test_metrics

def evaluate_model_performance(
    model_path: str,
    dataset_dir: str,
    output_dir: str,
    model_config: Dict
):
    """
    Evaluate trained model performance
    
    Args:
        model_path: Path to trained model
        dataset_dir: Directory containing test data
        output_dir: Output directory for evaluation results
        model_config: Model configuration
    """
    logger = setup_logging()
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Initialize inference engine
    logger.info("Initializing inference engine...")
    inference_engine = InferenceEngine(
        model_path=model_path,
        model_config=model_config,
        device='auto'
    )
    
    # Initialize post-processor
    post_processor = PostProcessor()
    
    # Load test data
    test_dataset = PseudoLabelDataset(dataset_dir, 'test')
    
    logger.info(f"Found {len(test_dataset)} test images")
    
    # Evaluation metrics
    metrics = SegmentationMetrics()
    all_metrics = []
    
    # Process each test image with progress bar
    with tqdm(total=len(test_dataset), desc="Evaluating model", unit="image") as pbar:
        for i in range(len(test_dataset)):
            sample = test_dataset[i]
            image_path = sample['image_path']
            mask_path = sample['mask_path']
            
            # Load ground truth mask
            gt_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            gt_mask = (gt_mask > 127).astype(np.uint8)
            
            # Run inference
            try:
                # Load and preprocess image
                image = cv2.imread(image_path)
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # Run inference
                prediction = inference_engine.predict(image)
                
                # Post-process prediction
                processed_mask = post_processor.apply_full_pipeline(prediction)
                
                # Ensure same size
                if processed_mask.shape != gt_mask.shape:
                    processed_mask = cv2.resize(processed_mask, (gt_mask.shape[1], gt_mask.shape[0]))
                
                # Binarize
                processed_mask = (processed_mask > 0.5).astype(np.uint8)
                
                # Calculate metrics
                sample_metrics = metrics.calculate_metrics(processed_mask, gt_mask)
                all_metrics.append(sample_metrics)
                
                pbar.set_postfix({
                    'IoU': f"{sample_metrics['iou']:.3f}",
                    'Dice': f"{sample_metrics['dice']:.3f}",
                    'processed': i + 1
                })
                
            except Exception as e:
                logger.error(f"Error processing {image_path}: {e}")
                pbar.set_postfix({'error': 'processing_failed'})
            
            pbar.update(1)
    
    # Calculate average metrics
    if all_metrics:
        avg_metrics = {}
        for key in all_metrics[0].keys():
            avg_metrics[key] = np.mean([m[key] for m in all_metrics])
        
        logger.info("Average Test Metrics:")
        for metric, value in avg_metrics.items():
            logger.info(f"  - {metric}: {value:.4f}")
        
        # Save evaluation results
        evaluation_results = {
            'average_metrics': avg_metrics,
            'individual_metrics': all_metrics,
            'num_samples': len(all_metrics)
        }
        
        with open(output_path / 'evaluation_results.json', 'w') as f:
            json.dump(evaluation_results, f, indent=2)
        
        return avg_metrics
    else:
        logger.error("No successful evaluations!")
        return None

def integrate_model_into_inference(
    model_path: str,
    model_config: Dict,
    output_dir: str
):
    """
    Integrate trained model into our inference system
    
    Args:
        model_path: Path to trained model
        model_config: Model configuration
        output_dir: Output directory for integration
    """
    logger = setup_logging()
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Test inference engine with trained model
    logger.info("Testing inference engine with trained model...")
    
    try:
        inference_engine = InferenceEngine(
            model_path=model_path,
            model_config=model_config,
            device='auto'
        )
        
        # Test with a sample image
        test_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        prediction = inference_engine.predict(test_image)
        
        logger.info(f"Inference test successful! Prediction shape: {prediction.shape}")
        
        # Save model info
        model_info = inference_engine.get_model_info()
        
        integration_results = {
            'model_path': str(model_path),
            'model_config': model_config,
            'model_info': model_info,
            'integration_status': 'success'
        }
        
        with open(output_path / 'integration_results.json', 'w') as f:
            json.dump(integration_results, f, indent=2)
        
        logger.info("Model successfully integrated into inference system!")
        return True
        
    except Exception as e:
        logger.error(f"Integration failed: {e}")
        
        integration_results = {
            'model_path': str(model_path),
            'model_config': model_config,
            'integration_status': 'failed',
            'error': str(e)
        }
        
        with open(output_path / 'integration_results.json', 'w') as f:
            json.dump(integration_results, f, indent=2)
        
        return False

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='Train building segmentation model with pseudo-labels')
    parser.add_argument('--dataset-dir', type=str, required=True,
                        help='Directory containing pseudo-label dataset')
    parser.add_argument('--output-dir', type=str, required=True,
                        help='Output directory for training results')
    parser.add_argument('--model-type', type=str, default='unet_basic',
                        choices=['unet_basic', 'resnet34_unet', 'resnet50_unet', 'efficientnet_b0_unet', 'efficientnet_b3_unet'],
                        help='Type of model to train')
    parser.add_argument('--epochs', type=int, default=50,
                        help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=8,
                        help='Batch size for training')
    parser.add_argument('--learning-rate', type=float, default=1e-4,
                        help='Learning rate')
    parser.add_argument('--quick-demo', action='store_true',
                        help='Run quick demo with reduced parameters')
    parser.add_argument('--skip-training', action='store_true',
                        help='Skip training and use existing model')
    parser.add_argument('--model-path', type=str,
                        help='Path to existing model (if skipping training)')
    
    args = parser.parse_args()
    
    # Create output directory
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    logger = setup_logging()
    logger.info("Starting pseudo-label training pipeline...")
    
    if args.skip_training and args.model_path:
        # Use existing model
        logger.info(f"Using existing model: {args.model_path}")
        model_path = args.model_path
        
        # Load model config from training results
        training_results_path = Path(args.model_path).parent / 'training_results.json'
        if training_results_path.exists():
            with open(training_results_path, 'r') as f:
                training_results = json.load(f)
            model_config = training_results['model_config']
        else:
            # Use default config
            model_configs = get_model_configs()
            model_config = model_configs[args.model_type].copy()
            model_config['input_channels'] = 3
            model_config['num_classes'] = 1
    else:
        # Train new model
        logger.info("Training new model with pseudo-labels...")
        model_path, test_metrics = train_model_with_pseudo_labels(
            dataset_dir=args.dataset_dir,
            output_dir=str(output_path / 'training'),
            model_type=args.model_type,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            quick_demo=args.quick_demo
        )
        
        # Load model config
        training_results_path = Path(model_path).parent / 'training_results.json'
        with open(training_results_path, 'r') as f:
            training_results = json.load(f)
        model_config = training_results['model_config']
    
    # Evaluate model
    logger.info("Evaluating model performance...")
    evaluation_metrics = evaluate_model_performance(
        model_path=model_path,
        dataset_dir=args.dataset_dir,
        output_dir=str(output_path / 'evaluation'),
        model_config=model_config
    )
    
    # Integrate into inference system
    logger.info("Integrating model into inference system...")
    integration_success = integrate_model_into_inference(
        model_path=model_path,
        model_config=model_config,
        output_dir=str(output_path / 'integration')
    )
    
    # Final summary
    logger.info("Pseudo-label training pipeline completed!")
    logger.info(f"Results saved to: {args.output_dir}")
    
    if evaluation_metrics:
        logger.info("Final Model Performance:")
        for metric, value in evaluation_metrics.items():
            logger.info(f"  - {metric}: {value:.4f}")
    
    if integration_success:
        logger.info("✅ Model successfully integrated into inference system!")
    else:
        logger.error("❌ Model integration failed!")

if __name__ == '__main__':
    main()
